# -*- coding: utf-8 -*-
"""Projet AI Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1S1qvvtRb9elXfcxpGYXmRznsbte5L1IX

#**Comparaison de trois algorithmes d'apprentissage automatique (SVM,kNN et RandomForest)**

###**Description** :
Cette étude vise à créer deux modèles d'intelligence artificielle pour la prédiction des maladies cardiaques en utilisant un ensemble de données préalablement collecté à partir de Kaggle. Les modèles sera entraîné à prédire les genres les plus susceptibles de développer des maladies cardiaques en fonction de plusieurs facteurs tels que l'âge, le rythme cardiaque, la glycémie, etc. Deux algorithmes d'apprentissage automatique seront comparés afin de déterminer celui offrant les meilleures performances pour cette tâche.

####**- Étape 1 : Collecte de données (ou téléchargement à partir de Kaggle)**

Ce jeu de données sur les maladies cardiaques est constitué en combinant 5 ensembles de données populaires sur les maladies cardiaques déjà disponibles indépendamment mais non combinés auparavant. Dans ce jeu de données, 5 ensembles de données sur les maladies cardiaques sont combinés sur 11 caractéristiques communes, ce qui en fait le plus grand jeu de données sur les maladies cardiaques disponible à ce jour à des fins de recherche. Les cinq ensembles de données utilisés pour sa création sont :

- Cleveland
- Hongrois
- Suisse
- Long Beach VA
- Ensemble de données Statlog (Heart)

Ce jeu de données se compose de 1190 instances avec 11 caractéristiques. Ces ensembles de données ont été collectés et combinés en un seul endroit pour aider à faire avancer la recherche sur les algorithmes d'apprentissage automatique et de fouille de données liés à la CAD, et espérons-le, pour faire progresser le diagnostic clinique et le traitement précoce.

### **- Étape 2 : Traitement des données**

Dans cette étape, les données sont préparées en les simplifiant si nécessaire, notamment en attribuant des valeurs binaires (1 et 0) à des champs qui peuvent varier. De plus, des méthodes telles que l'imputation des valeurs manquantes ou la suppression des colonnes contenant plusieurs champs vides sont utilisées pour garantir la qualité des données.
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import accuracy_score
import warnings
warnings.filterwarnings('ignore')

#Lecture d'un fichier CSV dans un DataFrame pandas.
df = pd.read_csv('/content/sample_data/heart_statlog_cleveland_hungary_final.csv')
df

df.info();

df.hist(figsize=(20,10),bins = 50);

# Calculer les pourcentages de cholesterol
min_cholesterol = df['cholesterol'].min()
max_cholesterol = df['cholesterol'].max()
df['cholesterol'] = ((df['cholesterol'] - min_cholesterol) / (max_cholesterol - min_cholesterol) * 100).map('{:.0f}'.format)
# Écrire le DataFrame mis à jour dans le fichier CSV (remplacement de l'ancienne colonne)
df

# Replace values in 'sex' column
df['sex'] = df['sex'].replace({'female': 0, 'male': 1})

# Replace values in 'target' column
df['target'] = df['target'].replace({'normal': 0, 'heart disease': 1})

# Afficher le DataFrame modifié
df

plt.figure(figsize=(20,10))
sns.heatmap(df.corr(),annot=True,cmap="coolwarm")

"""##**Observations :**


1. L'ensemble de données semble propre.
2. Toutes les valeurs sont numériques et non nulles.
3. La colonne 'target' est assez bien équilibrée.
4. La répartition de toutes les colonnes semble bien équilibrée. Seuls « cholestérol » et « oldpeak » pourraient avoir une distribution asymétrique avec de longues queues droites. Nous le vérifierons à l’aide de visualisations.
"""

# Définir une variable X pour les caractéristiques (features) du dataframe et y pour la colonne target.
X = df.drop('target', axis=1)
y = df['target']

# Diviser les données en ensembles d'entraînement et de test.
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)

"""##**Modélisation d'apprentissage automatique**

"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import cross_val_score

accuracies = []
best_k = None
knn_best_mean_score = 0

# Parcourir différentes valeurs de k pour trouver le nombre optimal de voisins pour le KNN
for k in range(1, 30):
    knn_model = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn_model, X, y, cv=5) # cv=5 means 5-fold cross-validation
    mean_score = scores.mean()
    print("k:", k, "Cross-Validation Scores:", scores, "Mean Score:", mean_score)
    accuracies.append(mean_score)
# Mettre à jour le meilleur score moyen et le meilleur k si un meilleur score moyen est trouvé
    if mean_score > knn_best_mean_score:
        knn_best_mean_score = mean_score
        best_k = k

# Affichage des resultas
plt.figure(figsize=(10, 6))
plt.plot(range(1, 30), accuracies, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)
plt.title('mean_score vs. K Value')
plt.xlabel('K Value')
plt.ylabel('mean_score')
plt.xticks(np.arange(1, 30, step=1))
plt.grid()
plt.show()

print("Best K:", best_k, "with Accuracy:", knn_best_mean_score)

#implimenté le knn classifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score

cancer_predect = KNeighborsClassifier(n_neighbors=best_k)
cancer_predect.fit(X_train,  y_train)
predicted = cancer_predect.predict(X_test)


accuracy = accuracy_score(predicted,y_test)
print("KNN Accuracy Score: ",accuracy)

conf_matrix = confusion_matrix(y_test, predicted)

# Tracer la matrice de confusion sous forme de heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

from sklearn import svm


# Entraîner des modèles SVM avec différents noyaux.
kernels = ['linear', 'poly', 'rbf', 'sigmoid']
accuracies = []
svm_best_accuracy = 0
best_kernel = None
svm_best_mean_score = 0

for kernel in kernels:
    model = svm.SVC(kernel=kernel)

    scores = cross_val_score(model,  X, y, cv=5)  # cv=5 means 5-fold cross-validation
    print("Kernel " + kernel +" Cross-Validation Scores:", scores)
    mean_score = scores.mean()
    accuracies.append(mean_score)
    if mean_score > svm_best_mean_score:
      svm_best_mean_score = mean_score
      best_kernel = kernel

# affichage les scores d'accuracy
plt.figure(figsize=(6, 4))
plt.plot(range(1, len(kernels) + 1), accuracies, marker='o', linestyle='-')
plt.title('la moyonne des différents noyaux SVM')
plt.xlabel('Noyau SVM')
plt.ylabel('Mean_score')
plt.xticks(range(1, len(kernels) + 1), kernels)
plt.grid(True)
plt.show()

from sklearn import svm
from sklearn.metrics import accuracy_score

# noyau Linear
model_linear = svm.SVC(kernel=best_kernel)
model_linear.fit(X_train, y_train)
y_pred_linear = model_linear.predict(X_test)


accuracy_linear = accuracy_score(y_test, y_pred_linear)
print(best_kernel,"Kernel Accuracy Score:", accuracy_linear)

conf_matrix = confusion_matrix(y_test, y_pred_linear)

# Tracer la matrice de confusion sous forme de carte thermique.
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()

from sklearn.svm import SVC


# Create and train the SVM classifier
svm_classifier = SVC(kernel=best_kernel)
svm_classifier.fit(X_train, y_train)

# Weights and bias obtained from the trained SVM classifier
weights = svm_classifier.coef_[0]
bias = svm_classifier.intercept_[0]

# New fruit to classify

res =svm_classifier.predict(X_test);
print(res);
print(bias);
print(weights);

from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score

params = {
    'criterion': ['gini', 'entropy'],
    'n_estimators': [100, 200, 300, 400]
}

accuracies = []
best_params = {}
rf_best_mean_score = 0

# Loop over each parameter combination
for criterion in params['criterion']:
    for n_estimators in params['n_estimators']:

        # Instantiate the RandomForestClassifier model with current parameters
        rf_model = RandomForestClassifier(criterion=criterion, n_estimators=n_estimators, random_state=33)

        # Perform cross-validation
        scores = cross_val_score(rf_model,  X, y, cv=5)

        # Calculate the mean accuracy
        mean_score = scores.mean()

        print("Criterion:", criterion, "n_estimators:", n_estimators, "Cross-Validation Scores:", scores, "Mean Score:", mean_score)

        accuracies.append(mean_score)
        if mean_score > rf_best_mean_score:
            rf_best_mean_score = mean_score
            best_params = {'criterion': criterion, 'n_estimators': n_estimators}

# Plotting the results
plt.figure(figsize=(10, 6))
plt.plot(range(len(accuracies)), accuracies, color='blue', linestyle='dashed', marker='o', markerfacecolor='red', markersize=10)
plt.title('Accuracy vs. Parameter Combination Index')
plt.xlabel('Parameter Combination Index')
plt.ylabel('Accuracy')
plt.xticks(np.arange(len(accuracies)), rotation=45)
plt.grid()
plt.show()

print("Best Parameters:", best_params)
print("Best Score:", rf_best_mean_score)

from sklearn.ensemble import RandomForestClassifier
RandomForestClassifierModel = RandomForestClassifier(criterion = 'entropy',n_estimators=200,random_state=33) #criterion can be also : gini
RandomForestClassifierModel.fit(X_train, y_train);
y_pred = RandomForestClassifierModel.predict(X_test);

accuracy = accuracy_score(y_pred,y_test)
print("Accuracy Score:",accuracy);


conf_matrix = confusion_matrix(y_test, y_pred)

# Plot confusion matrix as heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', cbar=False)
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()